{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22d129a-4cb7-4c7c-8ee0-354b5c1045a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smorrin/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/smorrin/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /Users/smorrin/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <2A8DB508-8AAF-3FF1-BDFE-9EF17CC2B482> /Users/smorrin/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe0697b0-956f-465d-a045-3c5f3c26e1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/Users/smorrin/Coding/AI/DeforestationTUMAI/archive/train')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path.cwd()  / \"archive\" / \"train\"; path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "44015e91-6f05-4fe1-9c64-1193e504baee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2448, 2448])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "661d2092-b909-4e4c-aded-0c2dd058fe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "om = pil_to_tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "1b861f98-35ec-4aa3-ba8c-d06cf7c6c634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 96, 128])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "om.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0e4f2522-b404-4087-8aa2-3156b2691cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  4,  4,  ..., 21, 21, 21],\n",
       "        [ 4,  4,  4,  ..., 21, 21, 21],\n",
       "        [ 4,  4,  4,  ..., 21, 21, 21],\n",
       "        ...,\n",
       "        [19, 19, 19,  ..., 17, 17, 17],\n",
       "        [19, 19, 19,  ..., 17, 17, 17],\n",
       "        [19, 19, 19,  ..., 17, 17, 17]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "om[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "cbd1046e-52b9-4f92-912a-bc49c90c7bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  4,  4,  ..., 21, 21, 21],\n",
       "        [ 4,  4,  4,  ..., 21, 21, 21],\n",
       "        [ 4,  4,  4,  ..., 21, 21, 21],\n",
       "        ...,\n",
       "        [19, 19, 19,  ..., 17, 17, 17],\n",
       "        [19, 19, 19,  ..., 17, 17, 17],\n",
       "        [19, 19, 19,  ..., 17, 17, 17]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "om[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "9b464282-3bfa-4c93-8627-5dfa9d191dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  4,  4,  ..., 21, 21, 21],\n",
       "        [ 4,  4,  4,  ..., 21, 21, 21],\n",
       "        [ 4,  4,  4,  ..., 21, 21, 21],\n",
       "        ...,\n",
       "        [19, 19, 19,  ..., 17, 17, 17],\n",
       "        [19, 19, 19,  ..., 17, 17, 17],\n",
       "        [19, 19, 19,  ..., 17, 17, 17]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "om[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d1b7087d-0f56-42f2-8e2d-a25fcf74a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tp = img_tens.permute(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c6e509a2-1bcc-470b-8438-5a78b18687ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0,   0, 255],\n",
       "         [  0,   0, 255],\n",
       "         [  0,   0, 255],\n",
       "         ...,\n",
       "         [  0,   0, 255],\n",
       "         [  0,   0, 255],\n",
       "         [  0,   0, 255]],\n",
       "\n",
       "        [[  0,   0, 255],\n",
       "         [  0,   0, 255],\n",
       "         [  0,   0, 255],\n",
       "         ...,\n",
       "         [  0,   0, 255],\n",
       "         [  0,   0, 255],\n",
       "         [  0,   0, 255]],\n",
       "\n",
       "        [[  0,   0, 255],\n",
       "         [  0,   0, 255],\n",
       "         [  0,   0, 255],\n",
       "         ...,\n",
       "         [  0,   0, 255],\n",
       "         [  0,   0, 255],\n",
       "         [  0,   0, 255]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], device='mps:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tp.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0740d96d-e954-442f-b030-0b34bce4442e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 255, 255],\n",
       "        [255, 255,   0],\n",
       "        [255,   0, 255],\n",
       "        [  0, 255,   0],\n",
       "        [  0,   0, 255],\n",
       "        [255, 255, 255],\n",
       "        [  0,   0,   0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_codes = tensor([\n",
    "    [0, 255, 255],\n",
    "    [255, 255, 0],\n",
    "    [255, 0, 255],\n",
    "    [0, 255, 0],\n",
    "    [0, 0, 255],\n",
    "    [255, 255, 255],\n",
    "    [0, 0, 0]\n",
    "], dtype=torch.uint8); replace_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a62e5fd5-be1e-4f94-87fe-7d1e0e913360",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(replace_codes)):\n",
    "    replace_vec = replace_codes[i]\n",
    "    bitmatrix = torch.all(img_tp == replace_vec, dim=2)\n",
    "    img_tp[bitmatrix] = tensor([i] * 3, dtype=img_tp.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c3d5457b-6309-4d60-888f-6aa38ba0a245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4, 4, 4],\n",
       "         [4, 4, 4],\n",
       "         [4, 4, 4],\n",
       "         ...,\n",
       "         [4, 4, 4],\n",
       "         [4, 4, 4],\n",
       "         [4, 4, 4]],\n",
       "\n",
       "        [[4, 4, 4],\n",
       "         [4, 4, 4],\n",
       "         [4, 4, 4],\n",
       "         ...,\n",
       "         [4, 4, 4],\n",
       "         [4, 4, 4],\n",
       "         [4, 4, 4]],\n",
       "\n",
       "        [[4, 4, 4],\n",
       "         [4, 4, 4],\n",
       "         [4, 4, 4],\n",
       "         ...,\n",
       "         [4, 4, 4],\n",
       "         [4, 4, 4],\n",
       "         [4, 4, 4]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[5, 5, 5],\n",
       "         [5, 5, 5],\n",
       "         [5, 5, 5],\n",
       "         ...,\n",
       "         [5, 5, 5],\n",
       "         [5, 5, 5],\n",
       "         [5, 5, 5]],\n",
       "\n",
       "        [[5, 5, 5],\n",
       "         [5, 5, 5],\n",
       "         [5, 5, 5],\n",
       "         ...,\n",
       "         [5, 5, 5],\n",
       "         [5, 5, 5],\n",
       "         [5, 5, 5]],\n",
       "\n",
       "        [[5, 5, 5],\n",
       "         [5, 5, 5],\n",
       "         [5, 5, 5],\n",
       "         ...,\n",
       "         [5, 5, 5],\n",
       "         [5, 5, 5],\n",
       "         [5, 5, 5]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3f567c79-87c5-49ab-a1b4-65da8b383427",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_or = img_tp.permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae658d9b-7fdc-4817-8c54-433bfe2657cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "cdda3b60-8d7f-40cd-9a53-6aa272cdadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c8003ff7-200e-4057-8a73-fdb34c1f3ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_or_p = transform(img_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "680d924a-e35b-486f-bcb9-18db419f1958",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_or_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "000492c2-ae1f-4dbf-8579-456fc050dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = \"mps\"\n",
    "transform = T.ToPILImage()\n",
    "\n",
    "\n",
    "def preprocess_image(path):\n",
    "    pil_image = PILImage.create(path)\n",
    "    img_tensor = pil_to_tensor(pil_image).to(torch_device)\n",
    "    img_tensor = img_tensor.permute(1, 2, 0)\n",
    "    replace_codes = tensor([\n",
    "        [0, 255, 255],\n",
    "        [255, 255, 0],\n",
    "        [255, 0, 255],\n",
    "        [0, 255, 0],\n",
    "        [0, 0, 255],\n",
    "        [255, 255, 255],\n",
    "        [0, 0, 0]\n",
    "    ], dtype=torch.uint8).to(torch_device)\n",
    "    for i in range(len(replace_codes)):\n",
    "        replace_vec = replace_codes[i]\n",
    "        bitmatrix = torch.all(img_tensor == replace_vec, dim=2)\n",
    "        img_tensor[bitmatrix] = tensor([i] * 3, dtype=img_tensor.dtype).to(torch_device)\n",
    "    img_tensor = img_tensor.permute(2, 0, 1)\n",
    "    pil_img = transform(img_tensor)\n",
    "    return pil_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d312c5e-ff5b-408f-97b7-83e50e87a8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocess_image(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "225f78dc-eeb4-4b2e-b90a-3ea8e34cf622",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b619ca-090c-45e1-8701-afb49ace4b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
